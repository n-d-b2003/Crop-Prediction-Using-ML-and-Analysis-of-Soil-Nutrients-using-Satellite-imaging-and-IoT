{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7701596,"sourceType":"datasetVersion","datasetId":4495733}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-27T16:50:02.095954Z","iopub.execute_input":"2024-02-27T16:50:02.097027Z","iopub.status.idle":"2024-02-27T16:50:02.543906Z","shell.execute_reply.started":"2024-02-27T16:50:02.096981Z","shell.execute_reply":"2024-02-27T16:50:02.542883Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tp-sentinel/Final_merged_tp_sentinel.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import metrics\nfrom math import sqrt\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import KFold,RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler  \nimport math\nimport pandas as pd\nfrom keras import models, layers, optimizers, regularizers\nimport numpy as np\nimport random\nfrom sklearn import model_selection, preprocessing\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom joblib import dump","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:06:04.055706Z","iopub.execute_input":"2024-03-13T17:06:04.056040Z","iopub.status.idle":"2024-03-13T17:06:21.347309Z","shell.execute_reply.started":"2024-03-13T17:06:04.056015Z","shell.execute_reply":"2024-03-13T17:06:21.346495Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-13 17:06:08.418698: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-13 17:06:08.418792: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-13 17:06:08.569171: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset=pd.read_csv('/kaggle/input/tp-data/tp1_final.csv')\ndataset.head()\ndataset.dropna(inplace=True)\nprint(dataset.count())","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:06:21.348992Z","iopub.execute_input":"2024-03-13T17:06:21.349569Z","iopub.status.idle":"2024-03-13T17:06:21.372929Z","shell.execute_reply.started":"2024-03-13T17:06:21.349543Z","shell.execute_reply":"2024-03-13T17:06:21.371758Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"STATION        351\nDate           351\nBand1_Mean     351\nBand2_Mean     351\nBand3_Mean     351\nBand4_Mean     351\nBand5_Mean     351\nBand6_Mean     351\nBand7_Mean     351\nBand8_Mean     351\nBand9_Mean     351\nBand10_Mean    351\nBand11_Mean    351\nBand12_Mean    351\nBand13_Mean    351\nTEST VALUE     351\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"features = ['Band1_Mean','Band2_Mean','Band3_Mean','Band4_Mean','Band5_Mean','Band6_Mean','Band7_Mean','Band8_Mean','Band9_Mean','Band10_Mean','Band11_Mean','Band12_Mean','Band13_Mean']\nlabel = ['TEST VALUE']\n\nX = dataset.loc[:, features].values\ny = dataset.loc[:, label].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:06:46.948329Z","iopub.execute_input":"2024-03-13T17:06:46.949060Z","iopub.status.idle":"2024-03-13T17:06:46.958678Z","shell.execute_reply.started":"2024-03-13T17:06:46.949031Z","shell.execute_reply":"2024-03-13T17:06:46.957704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Apply StandardScaler to target variable (y)\nscaler_y = StandardScaler()\ny_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n\n# Define the kernel\nkernel = DotProduct() + WhiteKernel()\n\n# Create GaussianProcessRegressor with the defined kernel\nregressor = GaussianProcessRegressor(kernel=kernel)\n\n# Fit the regressor on the training data\nregressor.fit(X_train, y_train_scaled)\n\n# Make predictions on the test set\npredictions_scaled = regressor.predict(X_test)\n\n# Inverse transform predictions to original scale for evaluation\npredictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1, 1)).ravel()\n\n# Evaluate the model\nr2 = r2_score(y_test, predictions)\nmse = mean_squared_error(y_test, predictions)\n\nprint(f'R-squared (R2): {r2}')\nprint(f'Mean Squared Error: {mse}')\n\nmodel_filename = 'TP-gaussian.joblib'\n\n# Save the model using joblib\ndump(regressor, model_filename)\n\n# Print a message indicating the successful save\nprint(f'Model saved as {model_filename}')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:06:49.164815Z","iopub.execute_input":"2024-03-13T17:06:49.165754Z","iopub.status.idle":"2024-03-13T17:06:50.035715Z","shell.execute_reply.started":"2024-03-13T17:06:49.165717Z","shell.execute_reply":"2024-03-13T17:06:50.034409Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"R-squared (R2): 0.6488239192016922\nMean Squared Error: 0.013173246642966872\nModel saved as TP-gaussian.joblib\n","output_type":"stream"}]},{"cell_type":"code","source":"svr_model = SVR(kernel='rbf')\n\nparam_dist = {\n    'C': [x for x in range(1, 10001, 1)],\n    'epsilon': [x for x in np.arange(0.0001, 1, 0.001)]\n}\n\nrandom_search = RandomizedSearchCV(SVR(), param_distributions=param_dist, n_iter=200, cv=5, scoring='neg_mean_squared_error', random_state=42)\nrandom_search.fit(X_train, y_train)\n\nrandomDf = pd.DataFrame(random_search.cv_results_)\nbest_svr_model = random_search.best_estimator_\n\ny_pred = best_svr_model.predict(X_test)\n\ntest_mse = mean_squared_error(y_test, y_pred)\ntest_r2 = r2_score(y_test, y_pred)\ntest_mae = mean_absolute_error(y_test, y_pred)\ntest_mape = mean_absolute_percentage_error(y_test, y_pred) * 100\ntest_rmse = np.sqrt(test_mse)\nbias = best_svr_model.intercept_\n\nprint(f\"Best Parameters: {random_search.best_params_}\")\nprint(f\"Overall R-squared (R2) Score on Test Set: {test_r2 * 100}\")\nprint(f\"Overall RMSE on Test Set: {test_rmse}\")\nprint(f\"Overall MAE on Test Set: {test_mae}\")\nprint(f\"Overall MAPE on Test Set: {test_mape}\")\nprint(f\"Overall Bias (Intercept): {bias}\")\n\nsvr_model_filename = 'TP-svr.joblib'\ndump(best_svr_model, svr_model_filename)\nprint(f'Best SVR model saved as {svr_model_filename}')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:08:13.900773Z","iopub.execute_input":"2024-03-13T17:08:13.901142Z","iopub.status.idle":"2024-03-13T17:08:40.123160Z","shell.execute_reply.started":"2024-03-13T17:08:13.901112Z","shell.execute_reply":"2024-03-13T17:08:40.122233Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Best Parameters: {'epsilon': 0.08710000000000001, 'C': 62}\nOverall R-squared (R2) Score on Test Set: 47.78944095343576\nOverall RMSE on Test Set: 0.13994684739162985\nOverall MAE on Test Set: 0.09018457340647609\nOverall MAPE on Test Set: 17.63403659987859\nOverall Bias (Intercept): [0.79366812]\nBest SVR model saved as TP-svr.joblib\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import uniform, randint\nimport pandas as pd\n\n# Create AdaBoostRegressor\nadaboost_model = AdaBoostRegressor(random_state=42)\n\n# Define the parameter grid\nparam_dist = {\n    'n_estimators': randint(10, 200),\n    'learning_rate': uniform(0.01, 1.0),\n}\n\n# Create RandomizedSearchCV\nrandom_search = RandomizedSearchCV(adaboost_model, param_distributions=param_dist, n_iter=10, scoring='neg_mean_squared_error', cv=5, random_state=42)\n\n# Fit the model\nrandom_search.fit(X_train, y_train)\n\n# Get the best parameters\nbest_n_estimators = random_search.best_params_['n_estimators']\nbest_learning_rate = random_search.best_params_['learning_rate']\n\n# Train the model with the best parameters\nbest_adaboost_model = AdaBoostRegressor(n_estimators=best_n_estimators, learning_rate=best_learning_rate, random_state=42)\nbest_adaboost_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred = best_adaboost_model.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\nr2 = r2_score(y_test, y_pred)\n\nprint(f'R-squared (R2): {r2}')\n\nadaboost_model_filename = 'TP-adaboost.joblib'\ndump(best_adaboost_model, adaboost_model_filename)\nprint(f'Best AdaBoostRegressor model saved as {adaboost_model_filename}')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:07:10.845625Z","iopub.execute_input":"2024-03-13T17:07:10.846320Z","iopub.status.idle":"2024-03-13T17:07:19.420391Z","shell.execute_reply.started":"2024-03-13T17:07:10.846277Z","shell.execute_reply":"2024-03-13T17:07:19.419355Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Mean Squared Error: 0.023235604414378178\nR-squared (R2): 0.6488239192016922\nBest AdaBoostRegressor model saved as TP-adaboost.joblib\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n\n# Create DecisionTreeRegressor\ndecision_tree_regressor = DecisionTreeRegressor(random_state=42)\n\n# Define the parameter grid\nparam_dist = {\n    'max_depth': np.arange(1, 21),  # Adjust the range based on your preferences\n}\n\n# Create RandomizedSearchCV\nrandom_search = RandomizedSearchCV(decision_tree_regressor, param_distributions=param_dist, n_iter=10, scoring='neg_mean_squared_error', cv=5, random_state=42)\n\n# Fit the model\nrandom_search.fit(X_train, y_train)\n\n# Get the best parameter\nbest_max_depth = random_search.best_params_['max_depth']\n\n# Train the model with the best parameter\nbest_decision_tree_regressor = DecisionTreeRegressor(max_depth=best_max_depth, random_state=42)\nbest_decision_tree_regressor.fit(X_train, y_train)\n\n# Make predictions\ny_pred = best_decision_tree_regressor.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\nr2 = r2_score(y_test, y_pred)\nprint(f\"R^2 Score on Test Set: {r2}\")\n\ndecision_tree_model_filename = 'TP-DT.joblib'\ndump(best_decision_tree_regressor, decision_tree_model_filename)\nprint(f'Best DecisionTreeRegressor model saved as {decision_tree_model_filename}')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:07:19.421639Z","iopub.execute_input":"2024-03-13T17:07:19.421927Z","iopub.status.idle":"2024-03-13T17:07:19.589727Z","shell.execute_reply.started":"2024-03-13T17:07:19.421903Z","shell.execute_reply":"2024-03-13T17:07:19.588777Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Mean Squared Error: 0.026773461894631683\nR^2 Score on Test Set: 0.28626559022339604\nBest DecisionTreeRegressor model saved as TP-DT.joblib\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n# Assuming 'dataset' is your DataFrame\n\n# Define features and labels\nfeatures = ['Band1_Mean', 'Band2_Mean', 'Band3_Mean', 'Band4_Mean', 'Band5_Mean', 'Band6_Mean', 'Band7_Mean', 'Band8_Mean',\n            'Band9_Mean', 'Band10_Mean', 'Band11_Mean', 'Band12_Mean', 'Band13_Mean']\nlabel = ['TEST VALUE']\n\nX = dataset.loc[:, features].values\ny = dataset.loc[:, label].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features (important for neural networks)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Create MLPRegressor\nmlp_regressor = MLPRegressor(hidden_layer_sizes=(50000, ), activation='relu', solver='adam', max_iter=500, random_state=42)\n\n# Fit the model\nmlp_regressor.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = mlp_regressor.predict(X_test_scaled)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\nr2 = r2_score(y_test, y_pred)\nprint(f\"R^2 Score on Test Set: {r2}\")\n\nmlp_model_filename = 'TP-mlp.joblib'\ndump(mlp_regressor, mlp_model_filename)\nprint(f'MLPRegressor model saved as {mlp_model_filename}')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:09:27.410236Z","iopub.execute_input":"2024-03-13T17:09:27.410993Z","iopub.status.idle":"2024-03-13T17:09:58.897373Z","shell.execute_reply.started":"2024-03-13T17:09:27.410960Z","shell.execute_reply":"2024-03-13T17:09:58.896413Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Mean Squared Error: 0.024225789053944808\nR^2 Score on Test Set: 0.3541821629254166\nMLPRegressor model saved as TP-mlp.joblib\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import randint\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\n# Assuming 'dataset' is your DataFrame\n\n# Define features and labels\nfeatures = ['Band1_Mean', 'Band2_Mean', 'Band3_Mean', 'Band4_Mean', 'Band5_Mean', 'Band6_Mean', 'Band7_Mean', 'Band8_Mean',\n            'Band9_Mean', 'Band10_Mean', 'Band11_Mean', 'Band12_Mean', 'Band13_Mean']\nlabel = ['TP']\n\nX = dataset.loc[:, features].values\ny = dataset.loc[:, label].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features (important for neural networks)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Create MLPRegressor\nmlp_regressor = MLPRegressor(max_iter=500, random_state=42)\n\n# Define the parameter grid\nparam_dist = {\n    'hidden_layer_sizes': list(zip(np.arange(10, 70000, 10), np.arange(10, 70000, 10))),  # Adjust the range based on your preferences\n}\n\n# Create RandomizedSearchCV\nrandom_search = RandomizedSearchCV(mlp_regressor, param_distributions=param_dist, n_iter=10, scoring='r2', cv=5, random_state=42)\n\n# Fit the model\nrandom_search.fit(X_train_scaled, y_train)\n\n# Get the best parameter\nbest_hidden_layer_sizes = random_search.best_params_['hidden_layer_sizes']\n\n# Train the model with the best parameter\nbest_mlp_regressor = MLPRegressor(hidden_layer_sizes=best_hidden_layer_sizes, activation='relu', solver='adam', max_iter=500, random_state=42)\nbest_mlp_regressor.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = best_mlp_regressor.predict(X_test_scaled)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error: {mse}')\nr2 = r2_score(y_test, y_pred)\nprint(f\"R^2 Score on Test Set: {r2}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T09:40:45.857301Z","iopub.execute_input":"2024-02-27T09:40:45.860592Z"},"trusted":true},"execution_count":null,"outputs":[]}]}